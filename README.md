Este projeto √© um estudo de um pipeline ETL (Extract, Transform, Load) que consome dados fict√≠cios da API JSONPlaceholder, realiza transforma√ß√µes e os armazena em um banco de dados SQLite3.

Tecnologias e Bibliotecas Utilizadas
O projeto utiliza as seguintes bibliotecas:

deep_translator ‚Äì Para tradu√ß√£o autom√°tica de textos, caso necess√°rio.
json ‚Äì Para manipula√ß√£o de dados no formato JSON.
os ‚Äì Para opera√ß√µes no sistema de arquivos.
pandas ‚Äì Para processamento e an√°lise de dados.
papermill ‚Äì Para execu√ß√£o de notebooks parametrizados.
requests ‚Äì Para fazer requisi√ß√µes HTTP √† API JSONPlaceholder.
sqlite3 ‚Äì Para armazenamento dos dados em um banco de dados SQLite.
subprocess ‚Äì Para execu√ß√£o de processos externos.

Ao executar o pipeline ETL, o projeto criar√° automaticamente a seguinte estrutura de diret√≥rios:
üìÇ Projeto_ETL
‚îÇ-- main.py
‚îÇ-- üìÇ DataLake/          # Armazena os dados brutos e processados seguindo o m√©todo Medallion
‚îÇ-- üìÇ notebook_outputs/  # Armazena os outputs das execu√ß√µes do Papermill
‚îÇ-- database.sqlite       # Banco de dados SQLite com os dados processados

Como Executar o Projeto?
1. Baixe os arquivos do projeto e coloque-os em uma pasta dedicada.
2. Abra o terminal (CMD) e navegue at√© a pasta do projeto usando o comando cd <caminho_da_pasta>.
3. Execute o seguinte comando: python main.py

Isso iniciar√° o processo ETL completo, extraindo os dados da API, realizando as transforma√ß√µes necess√°rias e armazenando os resultados no SQLite3.

Consultando os Dados no SQLite3
Ap√≥s a execu√ß√£o, os dados estar√£o dispon√≠veis no banco de dados SQLite (database.sqlite). Voc√™ pode explor√°-los utilizando um cliente SQLite ou via linha de comando. Dessa forma, √© poss√≠vel cruzar informa√ß√µes entre users e todos.

Considera√ß√µes Finais
Este projeto serve como base para estudos de processos ETL, incluindo a utiliza√ß√£o de APIs p√∫blicas, transforma√ß√£o de dados e armazenamento em banco de dados. Ele pode ser expandido para incluir novas fontes de dados, mais valida√ß√µes e outras etapas do pipeline de dados.
Fique √† vontade para modificar e aprimorar conforme suas necessidades!
